{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "408d1479",
   "metadata": {},
   "source": [
    "# üöÄ EXECUTION INSTRUCTIONS - TWO RELIABLE AI DETECTION MODELS\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANT: Run cells in this exact order to avoid errors:**\n",
    "\n",
    "1. **Import Libraries** (Cell 2) - Run first  \n",
    "2. **Helper Functions** (Cell 3) - Run second\n",
    "3. **Load Dataset** (Cell 5) - Run third\n",
    "4. **Preprocess Text** (Cell 7) - Run fourth (optional for new models)\n",
    "5. **Feature Extraction** (Cell 9) - Run fifth (optional for new models)\n",
    "6. **üÜï NEW MODELS - Choose your approach:**\n",
    "   - **üéØ Load Hugging Face Models** (Cell 10) - **RECOMMENDED** - Load 2 reliable models\n",
    "   - **üìä Evaluate Models** (Cell 11) - Test models on your dataset\n",
    "   - **üíæ Save Models** (Cell 12) - Save for Streamlit compatibility\n",
    "   - **üß™ Test Models** (Cell 16) - Quick functionality test\n",
    "\n",
    "## ü§ñ **Two Reliable AI Detection Models:**\n",
    "\n",
    "1. **ü§ñ ChatGPT Detector RoBERTa** - ChatGPT-specific content detection  \n",
    "2. **üîç OpenAI Community RoBERTa** - OpenAI content detection\n",
    "\n",
    "**‚úÖ For Streamlit app compatibility, run Cells 10 ‚Üí 11 ‚Üí 12**\n",
    "\n",
    "**üéØ These models are pre-trained and don't need your dataset for training!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9efbee",
   "metadata": {},
   "source": [
    "# Advanced AI Text Detector - Two Reliable Hugging Face Models\n",
    "\n",
    "This notebook demonstrates how to detect whether text is AI-generated or human-written using two reliable pre-trained models from Hugging Face:\n",
    "\n",
    "## ü§ñ **Featured Models:**\n",
    "1. **ü§ñ ChatGPT Detector RoBERTa** - ChatGPT-specific content detection  \n",
    "2. **üîç OpenAI Community RoBERTa** - OpenAI content detection\n",
    "\n",
    "## üéØ **Key Features:**\n",
    "- **No training required** - Uses pre-trained models\n",
    "- **High accuracy** - State-of-the-art performance\n",
    "- **Fast inference** - Optimized for speed\n",
    "- **Streamlit compatible** - Ready for web deployment\n",
    "- **Reliable** - Only includes models that work consistently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392f0af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries for Advanced AI Text Detection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "import torch\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "# Install and import textstat for readability analysis\n",
    "try:\n",
    "    import textstat\n",
    "    print(\"‚úÖ textstat library loaded successfully\")\n",
    "except ImportError:\n",
    "    print(\"üì¶ Installing textstat library...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"textstat\"])\n",
    "    import textstat\n",
    "    print(\"‚úÖ textstat library installed and loaded\")\n",
    "\n",
    "# Download NLTK resources\n",
    "print(\"üì¶ Downloading essential NLTK resources...\")\n",
    "nltk_resources = ['punkt', 'wordnet', 'stopwords', 'vader_lexicon', 'averaged_perceptron_tagger', 'maxent_ne_chunker', 'words']\n",
    "for resource in nltk_resources:\n",
    "    try:\n",
    "        nltk.download(resource, quiet=True)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Warning: Could not download {resource}: {e}\")\n",
    "\n",
    "print(\"üöÄ All libraries loaded successfully for advanced AI text detection!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3006da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "def show_metrics(name, y_true, y_pred):\n",
    "    \"\"\"Display evaluation metrics for a model\"\"\"\n",
    "    print(f'--- {name} ---')\n",
    "    print('Accuracy:', accuracy_score(y_true, y_pred))\n",
    "    print('Precision:', precision_score(y_true, y_pred))\n",
    "    print('Recall:', recall_score(y_true, y_pred))\n",
    "    print('F1 Score:', f1_score(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "def simple_preprocess(text):\n",
    "    \"\"\"Simple text preprocessing for quick training\"\"\"\n",
    "    return str(text).lower().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f62a775",
   "metadata": {},
   "source": [
    "## Load Labeled Dataset\n",
    "\n",
    "Upload your CSV file with columns `text` and `label` (0 = Human, 1 = AI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d4e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the new dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset_path = \"Training_Essay_Data.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "print(\"Dataset loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da58d60b",
   "metadata": {},
   "source": [
    "## Preprocess Text\n",
    "\n",
    "Clean, tokenize, lemmatize, and remove stopwords from the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a377804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Text Preprocessing for AI vs Human Detection\n",
    "# Enhanced preprocessing with professional techniques to improve detection accuracy\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "from nltk.tree import Tree\n",
    "\n",
    "# Install and import textstat for readability analysis\n",
    "try:\n",
    "    import textstat\n",
    "    print(\"‚úÖ textstat library available\")\n",
    "except ImportError:\n",
    "    print(\"üì¶ Installing textstat library...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"textstat\"])\n",
    "    import textstat\n",
    "    print(\"‚úÖ textstat library installed\")\n",
    "\n",
    "# Download required NLTK resources\n",
    "print(\"üì¶ Downloading NLTK resources...\")\n",
    "nltk_downloads = ['punkt', 'punkt_tab', 'stopwords', 'wordnet', 'averaged_perceptron_tagger', \n",
    "                  'maxent_ne_chunker', 'words', 'vader_lexicon', 'omw-1.4']\n",
    "for resource in nltk_downloads:\n",
    "    try:\n",
    "        nltk.download(resource, quiet=True)\n",
    "    except:\n",
    "        pass  # Continue if download fails\n",
    "\n",
    "print(\"üîß Initializing advanced preprocessing components...\")\n",
    "\n",
    "# Initialize components\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "class AdvancedTextPreprocessor:\n",
    "    \"\"\"Advanced text preprocessing specifically designed for AI vs Human text detection\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.sia = SentimentIntensityAnalyzer()\n",
    "        \n",
    "        # AI-specific patterns (common in AI-generated text)\n",
    "        self.ai_patterns = [\n",
    "            r'\\b(furthermore|moreover|additionally|consequently|therefore|thus|hence)\\b',\n",
    "            r'\\b(in conclusion|to summarize|in summary|overall|ultimately)\\b',\n",
    "            r'\\b(it is important to note|it should be noted|it is worth mentioning)\\b',\n",
    "            r'\\b(various|numerous|several|multiple|different)\\b',\n",
    "            r'\\b(comprehensive|extensive|significant|substantial|considerable)\\b'\n",
    "        ]\n",
    "        \n",
    "        # Human-specific patterns (more common in human writing)\n",
    "        self.human_patterns = [\n",
    "            r'\\b(I think|I believe|I feel|in my opinion|personally)\\b',\n",
    "            r'\\b(actually|really|quite|pretty|sort of|kind of)\\b',\n",
    "            r'\\b(umm|uhh|well|like|you know)\\b',\n",
    "            r'\\b(amazing|awesome|terrible|horrible|love|hate)\\b'\n",
    "        ]\n",
    "    \n",
    "    def extract_linguistic_features(self, text):\n",
    "        \"\"\"Extract advanced linguistic features that distinguish AI from human text\"\"\"\n",
    "        if not text or pd.isna(text):\n",
    "            return {}\n",
    "        \n",
    "        text_str = str(text)\n",
    "        sentences = sent_tokenize(text_str)\n",
    "        words = word_tokenize(text_str.lower())\n",
    "        \n",
    "        features = {}\n",
    "        \n",
    "        # 1. Readability and complexity metrics\n",
    "        try:\n",
    "            features['flesch_reading_ease'] = textstat.flesch_reading_ease(text_str)\n",
    "            features['flesch_kincaid_grade'] = textstat.flesch_kincaid_grade(text_str)\n",
    "            features['automated_readability_index'] = textstat.automated_readability_index(text_str)\n",
    "            features['coleman_liau_index'] = textstat.coleman_liau_index(text_str)\n",
    "            features['gunning_fog'] = textstat.gunning_fog(text_str)\n",
    "        except:\n",
    "            features.update({\n",
    "                'flesch_reading_ease': 0, 'flesch_kincaid_grade': 0,\n",
    "                'automated_readability_index': 0, 'coleman_liau_index': 0, 'gunning_fog': 0\n",
    "            })\n",
    "        \n",
    "        # 2. Text structure features\n",
    "        features['sentence_count'] = len(sentences)\n",
    "        features['word_count'] = len(words)\n",
    "        features['avg_sentence_length'] = len(words) / max(len(sentences), 1)\n",
    "        features['avg_word_length'] = np.mean([len(word) for word in words]) if words else 0\n",
    "        \n",
    "        # 3. Punctuation and formatting analysis\n",
    "        punct_count = sum(1 for char in text_str if char in string.punctuation)\n",
    "        features['punctuation_ratio'] = punct_count / max(len(text_str), 1)\n",
    "        features['exclamation_count'] = text_str.count('!')\n",
    "        features['question_count'] = text_str.count('?')\n",
    "        features['comma_count'] = text_str.count(',')\n",
    "        features['semicolon_count'] = text_str.count(';')\n",
    "        features['colon_count'] = text_str.count(':')\n",
    "        \n",
    "        # 4. Vocabulary diversity and sophistication\n",
    "        unique_words = set(words)\n",
    "        features['vocabulary_diversity'] = len(unique_words) / max(len(words), 1)\n",
    "        \n",
    "        # Long words (indicator of AI formality)\n",
    "        long_words = [word for word in words if len(word) > 6]\n",
    "        features['long_word_ratio'] = len(long_words) / max(len(words), 1)\n",
    "        \n",
    "        # 5. Sentiment analysis\n",
    "        try:\n",
    "            sentiment = self.sia.polarity_scores(text_str)\n",
    "            features.update({\n",
    "                'sentiment_positive': sentiment['pos'],\n",
    "                'sentiment_negative': sentiment['neg'],\n",
    "                'sentiment_neutral': sentiment['neu'],\n",
    "                'sentiment_compound': sentiment['compound']\n",
    "            })\n",
    "        except:\n",
    "            features.update({\n",
    "                'sentiment_positive': 0, 'sentiment_negative': 0, \n",
    "                'sentiment_neutral': 1, 'sentiment_compound': 0\n",
    "            })\n",
    "        \n",
    "        # 6. Part-of-speech patterns\n",
    "        try:\n",
    "            pos_tags = pos_tag(words)\n",
    "            pos_counts = Counter(tag for word, tag in pos_tags)\n",
    "            total_pos = len(pos_tags)\n",
    "            \n",
    "            features['noun_ratio'] = (pos_counts.get('NN', 0) + pos_counts.get('NNS', 0) + \n",
    "                                     pos_counts.get('NNP', 0) + pos_counts.get('NNPS', 0)) / max(total_pos, 1)\n",
    "            features['verb_ratio'] = (pos_counts.get('VB', 0) + pos_counts.get('VBD', 0) + \n",
    "                                     pos_counts.get('VBG', 0) + pos_counts.get('VBN', 0) + \n",
    "                                     pos_counts.get('VBP', 0) + pos_counts.get('VBZ', 0)) / max(total_pos, 1)\n",
    "            features['adjective_ratio'] = (pos_counts.get('JJ', 0) + pos_counts.get('JJR', 0) + \n",
    "                                          pos_counts.get('JJS', 0)) / max(total_pos, 1)\n",
    "            features['adverb_ratio'] = (pos_counts.get('RB', 0) + pos_counts.get('RBR', 0) + \n",
    "                                       pos_counts.get('RBS', 0)) / max(total_pos, 1)\n",
    "        except:\n",
    "            features.update({'noun_ratio': 0, 'verb_ratio': 0, 'adjective_ratio': 0, 'adverb_ratio': 0})\n",
    "        \n",
    "        # 7. AI vs Human pattern detection\n",
    "        text_lower = text_str.lower()\n",
    "        features['ai_pattern_count'] = sum(len(re.findall(pattern, text_lower, re.IGNORECASE)) \n",
    "                                          for pattern in self.ai_patterns)\n",
    "        features['human_pattern_count'] = sum(len(re.findall(pattern, text_lower, re.IGNORECASE)) \n",
    "                                             for pattern in self.human_patterns)\n",
    "        \n",
    "        # 8. Repetition and consistency analysis\n",
    "        words_clean = [word for word in words if word.isalpha()]\n",
    "        if words_clean:\n",
    "            word_freq = Counter(words_clean)\n",
    "            features['most_common_word_freq'] = word_freq.most_common(1)[0][1] / len(words_clean)\n",
    "            features['hapax_legomena_ratio'] = sum(1 for count in word_freq.values() if count == 1) / len(word_freq)\n",
    "        else:\n",
    "            features['most_common_word_freq'] = 0\n",
    "            features['hapax_legomena_ratio'] = 0\n",
    "        \n",
    "        # 9. Sentence structure variety\n",
    "        sentence_lengths = [len(word_tokenize(sent)) for sent in sentences]\n",
    "        if sentence_lengths:\n",
    "            features['sentence_length_variance'] = np.var(sentence_lengths)\n",
    "            features['max_sentence_length'] = max(sentence_lengths)\n",
    "            features['min_sentence_length'] = min(sentence_lengths)\n",
    "        else:\n",
    "            features['sentence_length_variance'] = 0\n",
    "            features['max_sentence_length'] = 0\n",
    "            features['min_sentence_length'] = 0\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def clean_text_advanced(self, text):\n",
    "        \"\"\"Advanced text cleaning while preserving important linguistic features\"\"\"\n",
    "        if not text or pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        text = str(text)\n",
    "        \n",
    "        # Remove URLs and email addresses\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '[URL]', text, flags=re.MULTILINE)\n",
    "        text = re.sub(r'\\S+@\\S+', '[EMAIL]', text)\n",
    "        \n",
    "        # Normalize whitespace but preserve structure\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        # Remove excessive punctuation but keep sentence structure\n",
    "        text = re.sub(r'[!]{2,}', '!', text)\n",
    "        text = re.sub(r'[?]{2,}', '?', text)\n",
    "        text = re.sub(r'[.]{3,}', '...', text)\n",
    "        \n",
    "        # Normalize quotes using Unicode codes\n",
    "        text = re.sub(r'[\\u201C\\u201D\\u201E\\u00AB\\u00BB]', '\"', text)  # Double quotes\n",
    "        text = re.sub(r'[\\u2018\\u2019\\u201A]', \"'\", text)  # Single quotes\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def preprocess_for_detection(self, text):\n",
    "        \"\"\"Main preprocessing function for AI detection\"\"\"\n",
    "        # Clean text while preserving structure\n",
    "        cleaned = self.clean_text_advanced(text)\n",
    "        \n",
    "        # Tokenize and process\n",
    "        words = word_tokenize(cleaned.lower())\n",
    "        \n",
    "        # Remove stopwords and lemmatize, but keep some structure words that might be important\n",
    "        important_words = {'however', 'therefore', 'furthermore', 'moreover', 'nevertheless', \n",
    "                          'consequently', 'actually', 'really', 'personally', 'obviously'}\n",
    "        \n",
    "        processed_words = []\n",
    "        for word in words:\n",
    "            if word.isalpha():\n",
    "                if word not in self.stop_words or word in important_words:\n",
    "                    processed_words.append(self.lemmatizer.lemmatize(word))\n",
    "        \n",
    "        return ' '.join(processed_words)\n",
    "\n",
    "# Initialize the advanced preprocessor\n",
    "print(\"üöÄ Initializing Advanced Text Preprocessor...\")\n",
    "advanced_preprocessor = AdvancedTextPreprocessor()\n",
    "\n",
    "# Check if 'generated' column exists before proceeding\n",
    "if 'generated' in df.columns and len(df) > 0:\n",
    "    print(\"üîÑ Applying advanced preprocessing techniques...\")\n",
    "    \n",
    "    # Sample for testing to avoid memory issues\n",
    "    sample_size = min(1000, len(df))\n",
    "    df_sample = df.head(sample_size).copy()\n",
    "    \n",
    "    # Apply advanced preprocessing\n",
    "    print(\"üìù Extracting linguistic features...\")\n",
    "    df_sample['text_clean'] = df_sample['text'].apply(advanced_preprocessor.preprocess_for_detection)\n",
    "    \n",
    "    # Extract advanced linguistic features\n",
    "    print(\"üîç Analyzing linguistic patterns...\")\n",
    "    linguistic_features = df_sample['text'].apply(advanced_preprocessor.extract_linguistic_features)\n",
    "    \n",
    "    # Convert linguistic features to DataFrame\n",
    "    features_df = pd.DataFrame(linguistic_features.tolist())\n",
    "    \n",
    "    # Add features to main dataframe\n",
    "    for col in features_df.columns:\n",
    "        df_sample[f'feature_{col}'] = features_df[col]\n",
    "    \n",
    "    print(f\"‚úÖ Advanced preprocessing completed!\")\n",
    "    print(f\"üìä Processed {len(df_sample)} samples\")\n",
    "    print(f\"üìä Added {len(features_df.columns)} linguistic features\")\n",
    "    print(f\"üéØ Total features available: {len([col for col in df_sample.columns if col.startswith('feature_')])}\")\n",
    "    \n",
    "    # Copy results back to main dataframe for the processed samples\n",
    "    df = df_sample.copy()\n",
    "    \n",
    "    # Display sample of processed data\n",
    "    print(f\"\\nüìã Sample of processed data:\")\n",
    "    sample_cols = ['text', 'text_clean', 'generated'] + [col for col in df.columns if col.startswith('feature_')][:5]\n",
    "    available_cols = [col for col in sample_cols if col in df.columns]\n",
    "    display_df = df[available_cols].head(3)\n",
    "    for col in display_df.columns:\n",
    "        if col in ['text', 'text_clean']:\n",
    "            display_df.loc[:, col] = display_df[col].apply(lambda x: str(x)[:100] + \"...\" if len(str(x)) > 100 else str(x))\n",
    "    print(display_df.to_string(index=False))\n",
    "    \n",
    "    # Show some key linguistic features\n",
    "    if len(features_df) > 0:\n",
    "        print(f\"\\nüìà Key Linguistic Features Analysis:\")\n",
    "        print(f\"üéØ AI Pattern Count - Mean: {features_df.get('ai_pattern_count', pd.Series([0])).mean():.2f}\")\n",
    "        print(f\"üë§ Human Pattern Count - Mean: {features_df.get('human_pattern_count', pd.Series([0])).mean():.2f}\")\n",
    "        print(f\"üìö Avg Readability Score: {features_df.get('flesch_reading_ease', pd.Series([0])).mean():.2f}\")\n",
    "        print(f\"üìù Avg Sentence Length: {features_df.get('avg_sentence_length', pd.Series([0])).mean():.2f}\")\n",
    "        print(f\"üî§ Vocabulary Diversity: {features_df.get('vocabulary_diversity', pd.Series([0])).mean():.3f}\")\n",
    "else:\n",
    "    print(\"‚ùå Error: 'generated' column is missing from the dataset or dataset is empty.\")\n",
    "    print(\"Available columns:\", df.columns if 'df' in locals() else \"No dataset loaded\")\n",
    "\n",
    "print(\"\\nüéâ Advanced preprocessing setup completed!\")\n",
    "print(\"üîß Features include: readability, sentiment, POS patterns, AI/human markers, and more!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae02d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Feature Analysis and Visualization\n",
    "# Analyze the linguistic features to understand AI vs Human patterns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if 'df' in locals() and len(df) > 0 and 'generated' in df.columns:\n",
    "    print(\"üìä ADVANCED LINGUISTIC FEATURE ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get feature columns\n",
    "    feature_cols = [col for col in df.columns if col.startswith('feature_')]\n",
    "    \n",
    "    if len(feature_cols) > 0:\n",
    "        print(f\"üîç Analyzing {len(feature_cols)} linguistic features...\")\n",
    "        \n",
    "        # Separate AI and Human samples\n",
    "        ai_data = df[df['generated'] == 1]\n",
    "        human_data = df[df['generated'] == 0]\n",
    "        \n",
    "        print(f\"\\nüìà FEATURE COMPARISON (AI vs Human):\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Analyze key distinguishing features\n",
    "        key_features = [\n",
    "            'feature_ai_pattern_count', 'feature_human_pattern_count', \n",
    "            'feature_flesch_reading_ease', 'feature_avg_sentence_length',\n",
    "            'feature_vocabulary_diversity', 'feature_sentiment_compound',\n",
    "            'feature_long_word_ratio', 'feature_punctuation_ratio'\n",
    "        ]\n",
    "        \n",
    "        comparison_results = []\n",
    "        \n",
    "        for feature in key_features:\n",
    "            if feature in df.columns:\n",
    "                ai_mean = ai_data[feature].mean() if len(ai_data) > 0 else 0\n",
    "                human_mean = human_data[feature].mean() if len(human_data) > 0 else 0\n",
    "                difference = ai_mean - human_mean\n",
    "                \n",
    "                comparison_results.append({\n",
    "                    'Feature': feature.replace('feature_', '').replace('_', ' ').title(),\n",
    "                    'AI Mean': f\"{ai_mean:.3f}\",\n",
    "                    'Human Mean': f\"{human_mean:.3f}\",\n",
    "                    'Difference': f\"{difference:.3f}\",\n",
    "                    'AI Higher': \"‚úÖ\" if difference > 0 else \"‚ùå\"\n",
    "                })\n",
    "        \n",
    "        if comparison_results:\n",
    "            comparison_df = pd.DataFrame(comparison_results)\n",
    "            print(comparison_df.to_string(index=False))\n",
    "            \n",
    "            print(f\"\\nüéØ KEY INSIGHTS:\")\n",
    "            print(\"=\" * 30)\n",
    "            \n",
    "            # AI pattern analysis\n",
    "            if 'feature_ai_pattern_count' in df.columns:\n",
    "                ai_patterns_ai = ai_data['feature_ai_pattern_count'].mean() if len(ai_data) > 0 else 0\n",
    "                ai_patterns_human = human_data['feature_ai_pattern_count'].mean() if len(human_data) > 0 else 0\n",
    "                if ai_patterns_ai > ai_patterns_human:\n",
    "                    print(f\"ü§ñ AI texts use {ai_patterns_ai:.1f}x more formal transition words\")\n",
    "            \n",
    "            # Human pattern analysis  \n",
    "            if 'feature_human_pattern_count' in df.columns:\n",
    "                human_patterns_ai = ai_data['feature_human_pattern_count'].mean() if len(ai_data) > 0 else 0\n",
    "                human_patterns_human = human_data['feature_human_pattern_count'].mean() if len(human_data) > 0 else 0\n",
    "                if human_patterns_human > human_patterns_ai:\n",
    "                    print(f\"üë§ Human texts use {human_patterns_human:.1f}x more personal expressions\")\n",
    "            \n",
    "            # Readability analysis\n",
    "            if 'feature_flesch_reading_ease' in df.columns:\n",
    "                ai_readability = ai_data['feature_flesch_reading_ease'].mean() if len(ai_data) > 0 else 0\n",
    "                human_readability = human_data['feature_flesch_reading_ease'].mean() if len(human_data) > 0 else 0\n",
    "                print(f\"üìö AI readability: {ai_readability:.1f} vs Human: {human_readability:.1f}\")\n",
    "            \n",
    "            # Vocabulary diversity\n",
    "            if 'feature_vocabulary_diversity' in df.columns:\n",
    "                ai_vocab = ai_data['feature_vocabulary_diversity'].mean() if len(ai_data) > 0 else 0\n",
    "                human_vocab = human_data['feature_vocabulary_diversity'].mean() if len(human_data) > 0 else 0\n",
    "                print(f\"üî§ AI vocab diversity: {ai_vocab:.3f} vs Human: {human_vocab:.3f}\")\n",
    "            \n",
    "            print(f\"\\nüí° DETECTION RECOMMENDATIONS:\")\n",
    "            print(\"‚úÖ Use these features in combination with content analysis\")\n",
    "            print(\"‚úÖ Higher AI pattern count suggests AI generation\")\n",
    "            print(\"‚úÖ Lower vocabulary diversity may indicate AI\")\n",
    "            print(\"‚úÖ More formal language patterns suggest AI\")\n",
    "            print(\"‚úÖ Personal expressions suggest human writing\")\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  No comparable features found for analysis\")\n",
    "            \n",
    "        # Create a summary of all features for machine learning\n",
    "        print(f\"\\nüéØ FEATURE SUMMARY FOR ML MODELS:\")\n",
    "        print(f\"üìä Total features extracted: {len(feature_cols)}\")\n",
    "        print(f\"üìà Ready for enhanced model training with:\")\n",
    "        print(f\"   ‚Ä¢ Traditional TF-IDF features\")\n",
    "        print(f\"   ‚Ä¢ {len(feature_cols)} advanced linguistic features\")\n",
    "        print(f\"   ‚Ä¢ Combined feature space for superior accuracy\")\n",
    "        \n",
    "        # Save feature analysis\n",
    "        if comparison_results:\n",
    "            comparison_df.to_csv('advanced_feature_analysis.csv', index=False)\n",
    "            print(f\"\\nüíæ Saved feature analysis to 'advanced_feature_analysis.csv'\")\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ùå No advanced features found. Please run the preprocessing cell first.\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Dataset not available. Please load dataset and run preprocessing first.\")\n",
    "\n",
    "print(f\"\\nüöÄ Advanced feature analysis completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a766c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Feature Extraction - Combining TF-IDF with Advanced Linguistic Features\n",
    "# This creates a comprehensive feature space for superior AI detection\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack\n",
    "import numpy as np\n",
    "\n",
    "if 'df' in locals() and len(df) > 0 and 'generated' in df.columns and 'text_clean' in df.columns:\n",
    "    print(\"üîß ENHANCED FEATURE EXTRACTION\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Prepare text data\n",
    "    texts = df['text_clean'].fillna('')\n",
    "    labels = df['generated']\n",
    "    \n",
    "    print(f\"üìä Dataset: {len(texts)} samples\")\n",
    "    print(f\"ü§ñ AI samples: {sum(labels)} ({sum(labels)/len(labels)*100:.1f}%)\")\n",
    "    print(f\"üë§ Human samples: {len(labels) - sum(labels)} ({(len(labels) - sum(labels))/len(labels)*100:.1f}%)\")\n",
    "    \n",
    "    # 1. Traditional TF-IDF Features\n",
    "    print(f\"\\nüî§ Extracting TF-IDF features...\")\n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        max_features=5000,\n",
    "        min_df=2,\n",
    "        max_df=0.95,\n",
    "        ngram_range=(1, 3),  # Include unigrams, bigrams, and trigrams\n",
    "        stop_words='english',\n",
    "        sublinear_tf=True\n",
    "    )\n",
    "    \n",
    "    X_tfidf = tfidf_vectorizer.fit_transform(texts)\n",
    "    print(f\"‚úÖ TF-IDF features: {X_tfidf.shape[1]} dimensions\")\n",
    "    \n",
    "    # 2. Advanced Linguistic Features\n",
    "    print(f\"üß† Extracting advanced linguistic features...\")\n",
    "    feature_cols = [col for col in df.columns if col.startswith('feature_')]\n",
    "    \n",
    "    if len(feature_cols) > 0:\n",
    "        X_linguistic = df[feature_cols].fillna(0).values\n",
    "        \n",
    "        # Standardize linguistic features\n",
    "        scaler = StandardScaler()\n",
    "        X_linguistic_scaled = scaler.fit_transform(X_linguistic)\n",
    "        \n",
    "        print(f\"‚úÖ Linguistic features: {X_linguistic_scaled.shape[1]} dimensions\")\n",
    "        \n",
    "        # 3. Combine All Features\n",
    "        print(f\"üîó Combining feature spaces...\")\n",
    "        \n",
    "        # Convert linguistic features to sparse format for combination\n",
    "        from scipy.sparse import csr_matrix\n",
    "        X_linguistic_sparse = csr_matrix(X_linguistic_scaled)\n",
    "        \n",
    "        # Combine TF-IDF and linguistic features\n",
    "        X_combined = hstack([X_tfidf, X_linguistic_sparse])\n",
    "        \n",
    "        print(f\"‚úÖ Combined features: {X_combined.shape[1]} dimensions\")\n",
    "        print(f\"   ‚Ä¢ TF-IDF: {X_tfidf.shape[1]} features\")\n",
    "        print(f\"   ‚Ä¢ Linguistic: {X_linguistic_scaled.shape[1]} features\")\n",
    "        \n",
    "        # 4. Train-Test Split with Enhanced Features\n",
    "        print(f\"\\nüìä Creating train-test split...\")\n",
    "        X_train_enhanced, X_test_enhanced, y_train, y_test = train_test_split(\n",
    "            X_combined, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "        )\n",
    "        \n",
    "        # Also create separate feature sets for comparison\n",
    "        X_train_tfidf, X_test_tfidf, _, _ = train_test_split(\n",
    "            X_tfidf, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "        )\n",
    "        \n",
    "        X_train_linguistic, X_test_linguistic, _, _ = train_test_split(\n",
    "            X_linguistic_scaled, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Train set: {X_train_enhanced.shape[0]} samples\")\n",
    "        print(f\"‚úÖ Test set: {X_test_enhanced.shape[0]} samples\")\n",
    "        \n",
    "        # 5. Feature Importance Analysis\n",
    "        print(f\"\\nüéØ FEATURE SPACE ANALYSIS:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Analyze linguistic feature importance\n",
    "        if len(feature_cols) > 0:\n",
    "            feature_names = [col.replace('feature_', '') for col in feature_cols]\n",
    "            linguistic_means = np.abs(X_linguistic_scaled).mean(axis=0)\n",
    "            \n",
    "            # Get top linguistic features\n",
    "            top_indices = np.argsort(linguistic_means)[-10:][::-1]\n",
    "            \n",
    "            print(f\"üîç Top 10 Most Variable Linguistic Features:\")\n",
    "            for i, idx in enumerate(top_indices, 1):\n",
    "                if idx < len(feature_names):\n",
    "                    print(f\"   {i:2d}. {feature_names[idx]}: {linguistic_means[idx]:.3f}\")\n",
    "        \n",
    "        # Save enhanced features for model training\n",
    "        print(f\"\\nüíæ Saving enhanced feature sets...\")\n",
    "        \n",
    "        # Save using numpy for sparse matrices\n",
    "        from scipy.sparse import save_npz\n",
    "        save_npz('X_train_enhanced.npz', X_train_enhanced)\n",
    "        save_npz('X_test_enhanced.npz', X_test_enhanced)\n",
    "        save_npz('X_train_tfidf.npz', X_train_tfidf) \n",
    "        save_npz('X_test_tfidf.npz', X_test_tfidf)\n",
    "        \n",
    "        # Save dense arrays\n",
    "        np.save('X_train_linguistic.npy', X_train_linguistic)\n",
    "        np.save('X_test_linguistic.npy', X_test_linguistic)\n",
    "        np.save('y_train.npy', y_train)\n",
    "        np.save('y_test.npy', y_test)\n",
    "        \n",
    "        # Save vectorizer and scaler\n",
    "        import joblib\n",
    "        joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer_enhanced.pkl')\n",
    "        joblib.dump(scaler, 'linguistic_scaler.pkl')\n",
    "        \n",
    "        print(f\"‚úÖ Enhanced feature sets saved!\")\n",
    "        print(f\"üìÅ Files created:\")\n",
    "        print(f\"   ‚Ä¢ X_train_enhanced.npz - Combined training features\")\n",
    "        print(f\"   ‚Ä¢ X_test_enhanced.npz - Combined test features\") \n",
    "        print(f\"   ‚Ä¢ tfidf_vectorizer_enhanced.pkl - TF-IDF vectorizer\")\n",
    "        print(f\"   ‚Ä¢ linguistic_scaler.pkl - Feature scaler\")\n",
    "        \n",
    "        # Global variables for immediate use\n",
    "        globals().update({\n",
    "            'X_train_enhanced': X_train_enhanced,\n",
    "            'X_test_enhanced': X_test_enhanced,\n",
    "            'X_train_tfidf': X_train_tfidf,\n",
    "            'X_test_tfidf': X_test_tfidf,\n",
    "            'X_train_linguistic': X_train_linguistic,\n",
    "            'X_test_linguistic': X_test_linguistic,\n",
    "            'y_train': y_train,\n",
    "            'y_test': y_test,\n",
    "            'tfidf_vectorizer': tfidf_vectorizer,\n",
    "            'linguistic_scaler': scaler\n",
    "        })\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå No advanced linguistic features found!\")\n",
    "        print(\"Please run the advanced preprocessing cell first.\")\n",
    "        \n",
    "        # Fallback to basic TF-IDF only\n",
    "        X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(\n",
    "            X_tfidf, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "        )\n",
    "        \n",
    "        globals().update({\n",
    "            'X_train_tfidf': X_train_tfidf,\n",
    "            'X_test_tfidf': X_test_tfidf,\n",
    "            'y_train': y_train,\n",
    "            'y_test': y_test,\n",
    "            'tfidf_vectorizer': tfidf_vectorizer\n",
    "        })\n",
    "        \n",
    "        print(\"‚ö†Ô∏è  Using basic TF-IDF features only.\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Dataset or preprocessed text not available!\")\n",
    "    print(\"Please ensure you have:\")\n",
    "    print(\"   ‚Ä¢ Loaded the dataset\")\n",
    "    print(\"   ‚Ä¢ Run the advanced preprocessing\")\n",
    "    print(\"   ‚Ä¢ Generated the 'text_clean' column\")\n",
    "\n",
    "print(f\"\\nüéâ Enhanced feature extraction completed!\")\n",
    "print(f\"üöÄ Ready for advanced model training with comprehensive features!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabe3ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Comparison: Basic vs Enhanced Features\n",
    "# Demonstrate the improvement from advanced preprocessing\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import time\n",
    "\n",
    "if 'y_train' in globals() and 'y_test' in globals():\n",
    "    print(\"üèÜ PERFORMANCE COMPARISON: Basic vs Enhanced Features\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results_comparison = []\n",
    "    \n",
    "    # Test 1: Basic TF-IDF only\n",
    "    if 'X_train_tfidf' in globals():\n",
    "        print(\"\\nüî§ Testing with Basic TF-IDF Features Only...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        lr_basic = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        lr_basic.fit(X_train_tfidf, y_train)\n",
    "        y_pred_basic = lr_basic.predict(X_test_tfidf)\n",
    "        \n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy_basic = accuracy_score(y_test, y_pred_basic)\n",
    "        precision_basic = precision_score(y_test, y_pred_basic, zero_division=0)\n",
    "        recall_basic = recall_score(y_test, y_pred_basic, zero_division=0)\n",
    "        f1_basic = f1_score(y_test, y_pred_basic, zero_division=0)\n",
    "        \n",
    "        results_comparison.append({\n",
    "            'Model': 'Basic TF-IDF',\n",
    "            'Accuracy': f\"{accuracy_basic:.4f}\",\n",
    "            'Precision': f\"{precision_basic:.4f}\",\n",
    "            'Recall': f\"{recall_basic:.4f}\",\n",
    "            'F1 Score': f\"{f1_basic:.4f}\",\n",
    "            'Training Time': f\"{train_time:.2f}s\",\n",
    "            'Features': X_train_tfidf.shape[1]\n",
    "        })\n",
    "        \n",
    "        print(f\"‚úÖ Basic Model Results:\")\n",
    "        print(f\"   Accuracy: {accuracy_basic:.4f} ({accuracy_basic*100:.2f}%)\")\n",
    "        print(f\"   F1 Score: {f1_basic:.4f}\")\n",
    "        print(f\"   Features: {X_train_tfidf.shape[1]}\")\n",
    "    \n",
    "    # Test 2: Linguistic features only\n",
    "    if 'X_train_linguistic' in globals():\n",
    "        print(\"\\nüß† Testing with Linguistic Features Only...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        lr_linguistic = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        lr_linguistic.fit(X_train_linguistic, y_train)\n",
    "        y_pred_linguistic = lr_linguistic.predict(X_test_linguistic)\n",
    "        \n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy_ling = accuracy_score(y_test, y_pred_linguistic)\n",
    "        precision_ling = precision_score(y_test, y_pred_linguistic, zero_division=0)\n",
    "        recall_ling = recall_score(y_test, y_pred_linguistic, zero_division=0)\n",
    "        f1_ling = f1_score(y_test, y_pred_linguistic, zero_division=0)\n",
    "        \n",
    "        results_comparison.append({\n",
    "            'Model': 'Linguistic Only',\n",
    "            'Accuracy': f\"{accuracy_ling:.4f}\",\n",
    "            'Precision': f\"{precision_ling:.4f}\",\n",
    "            'Recall': f\"{recall_ling:.4f}\",\n",
    "            'F1 Score': f\"{f1_ling:.4f}\",\n",
    "            'Training Time': f\"{train_time:.2f}s\",\n",
    "            'Features': X_train_linguistic.shape[1]\n",
    "        })\n",
    "        \n",
    "        print(f\"‚úÖ Linguistic Model Results:\")\n",
    "        print(f\"   Accuracy: {accuracy_ling:.4f} ({accuracy_ling*100:.2f}%)\")\n",
    "        print(f\"   F1 Score: {f1_ling:.4f}\")\n",
    "        print(f\"   Features: {X_train_linguistic.shape[1]}\")\n",
    "    \n",
    "    # Test 3: Enhanced combined features\n",
    "    if 'X_train_enhanced' in globals():\n",
    "        print(\"\\nüöÄ Testing with Enhanced Combined Features...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        lr_enhanced = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        lr_enhanced.fit(X_train_enhanced, y_train)\n",
    "        y_pred_enhanced = lr_enhanced.predict(X_test_enhanced)\n",
    "        \n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy_enh = accuracy_score(y_test, y_pred_enhanced)\n",
    "        precision_enh = precision_score(y_test, y_pred_enhanced, zero_division=0)\n",
    "        recall_enh = recall_score(y_test, y_pred_enhanced, zero_division=0)\n",
    "        f1_enh = f1_score(y_test, y_pred_enhanced, zero_division=0)\n",
    "        \n",
    "        results_comparison.append({\n",
    "            'Model': 'Enhanced Combined',\n",
    "            'Accuracy': f\"{accuracy_enh:.4f}\",\n",
    "            'Precision': f\"{precision_enh:.4f}\",\n",
    "            'Recall': f\"{recall_enh:.4f}\",\n",
    "            'F1 Score': f\"{f1_enh:.4f}\",\n",
    "            'Training Time': f\"{train_time:.2f}s\",\n",
    "            'Features': X_train_enhanced.shape[1]\n",
    "        })\n",
    "        \n",
    "        print(f\"‚úÖ Enhanced Model Results:\")\n",
    "        print(f\"   Accuracy: {accuracy_enh:.4f} ({accuracy_enh*100:.2f}%)\")\n",
    "        print(f\"   F1 Score: {f1_enh:.4f}\")\n",
    "        print(f\"   Features: {X_train_enhanced.shape[1]}\")\n",
    "        \n",
    "        # Calculate improvement\n",
    "        if 'accuracy_basic' in locals():\n",
    "            improvement = ((accuracy_enh - accuracy_basic) / accuracy_basic) * 100\n",
    "            print(f\"üìà Improvement over basic: {improvement:.2f}%\")\n",
    "    \n",
    "    # Display comparison table\n",
    "    if results_comparison:\n",
    "        print(f\"\\nüìä COMPREHENSIVE COMPARISON TABLE:\")\n",
    "        print(\"=\" * 80)\n",
    "        comparison_df = pd.DataFrame(results_comparison)\n",
    "        print(comparison_df.to_string(index=False))\n",
    "        \n",
    "        # Save comparison results\n",
    "        comparison_df.to_csv('feature_performance_comparison.csv', index=False)\n",
    "        print(f\"\\nüíæ Comparison saved to 'feature_performance_comparison.csv'\")\n",
    "        \n",
    "        # Analysis and recommendations\n",
    "        print(f\"\\nüéØ ANALYSIS & RECOMMENDATIONS:\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        if len(results_comparison) >= 3:\n",
    "            # Find best performing model\n",
    "            accuracies = [float(result['Accuracy']) for result in results_comparison]\n",
    "            best_idx = np.argmax(accuracies)\n",
    "            best_model = results_comparison[best_idx]['Model']\n",
    "            best_accuracy = accuracies[best_idx]\n",
    "            \n",
    "            print(f\"üèÜ Best Model: {best_model}\")\n",
    "            print(f\"üéØ Best Accuracy: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)\")\n",
    "            \n",
    "            if best_model == 'Enhanced Combined':\n",
    "                print(f\"‚úÖ Enhanced features provide the best performance!\")\n",
    "                print(f\"üí° The combination of TF-IDF and linguistic features is optimal\")\n",
    "            elif best_model == 'Linguistic Only':\n",
    "                print(f\"üß† Linguistic features alone outperform TF-IDF!\")\n",
    "                print(f\"üí° Style analysis is more important than content for this dataset\")\n",
    "            else:\n",
    "                print(f\"üìù Basic TF-IDF performs best for this dataset\")\n",
    "                print(f\"üí° Content words are more discriminative than style features\")\n",
    "        \n",
    "        print(f\"\\nüîç KEY INSIGHTS:\")\n",
    "        print(\"‚Ä¢ Advanced preprocessing captures writing style patterns\")\n",
    "        print(\"‚Ä¢ Linguistic features reveal AI vs human behavioral differences\")\n",
    "        print(\"‚Ä¢ Combined approach provides comprehensive analysis\")\n",
    "        print(\"‚Ä¢ Feature engineering significantly impacts detection accuracy\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå No models could be trained. Check feature extraction.\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Training/test data not available!\")\n",
    "    print(\"Please run the enhanced feature extraction cell first.\")\n",
    "\n",
    "print(f\"\\nüéâ Performance comparison completed!\")\n",
    "print(f\"üöÄ Use the best-performing approach for your AI detection models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e963bcb",
   "metadata": {},
   "source": [
    "## Advanced Feature Extraction and Analysis\n",
    "\n",
    "We will extract multiple types of features for comprehensive AI vs Human detection:\n",
    "- **Traditional TF-IDF features** for content analysis\n",
    "- **Advanced linguistic features** for writing style analysis\n",
    "- **Readability metrics** for complexity assessment\n",
    "- **Sentiment and emotional patterns** for human-like expression detection\n",
    "- **Syntactic patterns** for grammatical structure analysis\n",
    "\n",
    "This multi-dimensional approach significantly improves detection accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f6bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Two Reliable Hugging Face AI Detection Models with Progress Tracking\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "print(\"üöÄ INITIALIZING TWO RELIABLE HUGGING FACE AI DETECTION MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(f\"üñ•Ô∏è  Device: {'GPU (CUDA)' if device == 0 else 'CPU'}\")\n",
    "\n",
    "# Model configurations - ONLY THE 2 WORKING MODELS\n",
    "models_config = [\n",
    "    {\n",
    "        \"name\": \"ChatGPT Detector RoBERTa\",\n",
    "        \"model_id\": \"Hello-SimpleAI/chatgpt-detector-roberta\", \n",
    "        \"variable_name\": \"chatgpt_pipeline\",\n",
    "        \"description\": \"RoBERTa-based ChatGPT detection model\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"OpenAI Community RoBERTa Detector\",\n",
    "        \"model_id\": \"openai-community/roberta-base-openai-detector\",\n",
    "        \"variable_name\": \"openai_pipeline\", \n",
    "        \"description\": \"OpenAI's official RoBERTa-based AI detection model\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Initialize models with progress tracking\n",
    "initialized_models = {}\n",
    "\n",
    "for model_config in models_config:\n",
    "    print(f\"\\nüîÑ Loading: {model_config['name']}\")\n",
    "    print(f\"üìã Model ID: {model_config['model_id']}\")\n",
    "    print(f\"üìù Description: {model_config['description']}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        print(\"‚¨áÔ∏è  Downloading model (this may take a while for first-time downloads)...\")\n",
    "        \n",
    "        # Create progress bar for model loading\n",
    "        with tqdm(total=100, desc=f\"Loading {model_config['name']}\", \n",
    "                 bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]\") as pbar:\n",
    "            \n",
    "            # Initialize the pipeline\n",
    "            pipeline_model = pipeline(\n",
    "                \"text-classification\",\n",
    "                model=model_config['model_id'],\n",
    "                device=device,\n",
    "                return_all_scores=False\n",
    "            )\n",
    "            \n",
    "            pbar.update(100)\n",
    "        \n",
    "        # Store the pipeline\n",
    "        globals()[model_config['variable_name']] = pipeline_model\n",
    "        initialized_models[model_config['variable_name']] = pipeline_model\n",
    "        \n",
    "        load_time = time.time() - start_time\n",
    "        print(f\"‚úÖ Successfully loaded in {load_time:.2f} seconds\")\n",
    "        \n",
    "        # Test the model with a simple example\n",
    "        test_text = \"This is a test sentence to verify the model works correctly.\"\n",
    "        try:\n",
    "            test_result = pipeline_model(test_text)\n",
    "            print(f\"üß™ Test prediction: {test_result}\")\n",
    "        except Exception as test_error:\n",
    "            print(f\"‚ö†Ô∏è  Test prediction failed: {test_error}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load {model_config['name']}: {e}\")\n",
    "        globals()[model_config['variable_name']] = None\n",
    "        print(\"   This model will be skipped in evaluation.\")\n",
    "\n",
    "print(f\"\\nüìä MODEL INITIALIZATION SUMMARY\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"‚úÖ Successfully loaded: {len([m for m in initialized_models.values() if m is not None])} models\")\n",
    "print(f\"‚ùå Failed to load: {len([m for m in initialized_models.values() if m is None])} models\")\n",
    "\n",
    "if len([m for m in initialized_models.values() if m is not None]) > 0:\n",
    "    print(f\"\\nüéØ Ready for evaluation!\")\n",
    "    \n",
    "    # Display available models\n",
    "    print(f\"\\nüìã Available models for evaluation:\")\n",
    "    for var_name, model in initialized_models.items():\n",
    "        if model is not None:\n",
    "            config = next(c for c in models_config if c['variable_name'] == var_name)\n",
    "            print(f\"   ‚Ä¢ {config['name']} ({var_name})\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå No models available for evaluation!\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7eb67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Two Successful Hugging Face AI Detection Models\n",
    "# This cell loads only the 2 models that work reliably\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import torch\n",
    "import joblib\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"üöÄ Loading two reliable AI detection models...\")\n",
    "\n",
    "# Model 1: ChatGPT Detector RoBERTa\n",
    "print(\"\\nü§ñ Loading ChatGPT Detector RoBERTa...\")\n",
    "try:\n",
    "    chatgpt_tokenizer = AutoTokenizer.from_pretrained(\"Hello-SimpleAI/chatgpt-detector-roberta\")\n",
    "    chatgpt_model = AutoModelForSequenceClassification.from_pretrained(\"Hello-SimpleAI/chatgpt-detector-roberta\")\n",
    "    chatgpt_pipeline = pipeline(\"text-classification\", \n",
    "                                model=chatgpt_model, \n",
    "                                tokenizer=chatgpt_tokenizer,\n",
    "                                max_length=512,\n",
    "                                truncation=True)\n",
    "    print(\"‚úÖ ChatGPT Detector model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading ChatGPT Detector model: {e}\")\n",
    "    chatgpt_pipeline = None\n",
    "\n",
    "# Model 2: OpenAI Community RoBERTa Detector\n",
    "print(\"\\nüîç Loading OpenAI Community RoBERTa Detector...\")\n",
    "try:\n",
    "    openai_tokenizer = AutoTokenizer.from_pretrained(\"openai-community/roberta-base-openai-detector\")\n",
    "    openai_model = AutoModelForSequenceClassification.from_pretrained(\"openai-community/roberta-base-openai-detector\")\n",
    "    openai_pipeline = pipeline(\"text-classification\", \n",
    "                              model=openai_model, \n",
    "                              tokenizer=openai_tokenizer,\n",
    "                              max_length=512,\n",
    "                              truncation=True)\n",
    "    print(\"‚úÖ OpenAI Community model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading OpenAI Community model: {e}\")\n",
    "    openai_pipeline = None\n",
    "\n",
    "print(\"\\nüéØ Two models loaded! Ready for evaluation and saving...\")\n",
    "\n",
    "# Summary of loaded models\n",
    "successful_models = []\n",
    "if chatgpt_pipeline is not None:\n",
    "    successful_models.append(\"ChatGPT Detector RoBERTa\")\n",
    "if openai_pipeline is not None:\n",
    "    successful_models.append(\"OpenAI Community RoBERTa\")\n",
    "\n",
    "print(f\"\\nüìä LOADED MODELS SUMMARY:\")\n",
    "print(f\"‚úÖ Successfully loaded: {len(successful_models)} models\")\n",
    "for model in successful_models:\n",
    "    print(f\"   ‚Ä¢ {model}\")\n",
    "\n",
    "if len(successful_models) == 0:\n",
    "    print(\"‚ùå No models loaded successfully!\")\n",
    "else:\n",
    "    print(f\"\\nüöÄ Ready to use {len(successful_models)} reliable models!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1acf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and Record Training Progress for Two Successful Hugging Face Models\n",
    "# This cell provides detailed progress tracking and saves comprehensive results\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Initialize training log\n",
    "training_log = {\n",
    "    \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"models\": {},\n",
    "    \"overall_summary\": {}\n",
    "}\n",
    "\n",
    "print(\"üìä STARTING COMPREHENSIVE MODEL EVALUATION - 2 MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def evaluate_hf_model_with_progress(pipeline_model, model_name, model_id, texts, true_labels, max_samples=1000):\n",
    "    \"\"\"Evaluate a Hugging Face pipeline model with detailed progress tracking\"\"\"\n",
    "    \n",
    "    print(f\"\\nüîç EVALUATING: {model_name}\")\n",
    "    print(f\"üìã Model ID: {model_id}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    if pipeline_model is None:\n",
    "        print(f\"‚ùå {model_name} not available for evaluation\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Use subset for evaluation\n",
    "    sample_texts = texts[:max_samples].tolist()\n",
    "    sample_labels = true_labels[:max_samples].tolist()\n",
    "    \n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "    detailed_results = []\n",
    "    \n",
    "    print(f\"üìä Processing {len(sample_texts)} samples...\")\n",
    "    print(f\"‚è±Ô∏è  Started at: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    \n",
    "    # Progress tracking\n",
    "    batch_size = 50\n",
    "    total_batches = (len(sample_texts) + batch_size - 1) // batch_size\n",
    "    \n",
    "    for batch_idx in range(total_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min((batch_idx + 1) * batch_size, len(sample_texts))\n",
    "        batch_texts = sample_texts[start_idx:end_idx]\n",
    "        \n",
    "        batch_start = time.time()\n",
    "        \n",
    "        for i, text in enumerate(batch_texts):\n",
    "            global_idx = start_idx + i\n",
    "            try:\n",
    "                # Get prediction from pipeline\n",
    "                result = pipeline_model(text)\n",
    "                \n",
    "                # Handle different output formats\n",
    "                if isinstance(result, list) and len(result) > 0:\n",
    "                    result = result[0]\n",
    "                \n",
    "                # Extract label and score\n",
    "                label = result.get('label', 'UNKNOWN')\n",
    "                score = result.get('score', 0.5)\n",
    "                \n",
    "                # Convert labels to binary (1 = AI, 0 = Human)\n",
    "                if label.upper() in ['AI', 'MACHINE', 'GENERATED', 'FAKE', 'CHATGPT', 'LABEL_1', '1']:\n",
    "                    pred = 1\n",
    "                    ai_prob = score\n",
    "                elif label.upper() in ['HUMAN', 'REAL', 'AUTHENTIC', 'LABEL_0', '0']:\n",
    "                    pred = 0\n",
    "                    ai_prob = 1 - score\n",
    "                else:\n",
    "                    # Use score to determine (>0.5 means AI)\n",
    "                    pred = 1 if score > 0.5 else 0\n",
    "                    ai_prob = score if pred == 1 else 1 - score\n",
    "                \n",
    "                predictions.append(pred)\n",
    "                probabilities.append(ai_prob)\n",
    "                \n",
    "                # Store detailed result\n",
    "                detailed_results.append({\n",
    "                    'sample_id': global_idx,\n",
    "                    'true_label': sample_labels[global_idx],\n",
    "                    'predicted_label': pred,\n",
    "                    'ai_probability': ai_prob,\n",
    "                    'raw_label': label,\n",
    "                    'raw_score': score,\n",
    "                    'correct': sample_labels[global_idx] == pred\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error processing sample {global_idx}: {e}\")\n",
    "                predictions.append(0)  # Default to human\n",
    "                probabilities.append(0.5)\n",
    "                detailed_results.append({\n",
    "                    'sample_id': global_idx,\n",
    "                    'true_label': sample_labels[global_idx],\n",
    "                    'predicted_label': 0,\n",
    "                    'ai_probability': 0.5,\n",
    "                    'raw_label': 'ERROR',\n",
    "                    'raw_score': 0.5,\n",
    "                    'correct': sample_labels[global_idx] == 0,\n",
    "                    'error': str(e)\n",
    "                })\n",
    "        \n",
    "        batch_time = time.time() - batch_start\n",
    "        progress = (batch_idx + 1) / total_batches * 100\n",
    "        \n",
    "        print(f\"üìà Progress: {progress:.1f}% | Batch {batch_idx + 1}/{total_batches} | Time: {batch_time:.2f}s\")\n",
    "    \n",
    "    # Calculate comprehensive metrics\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    accuracy = accuracy_score(sample_labels, predictions)\n",
    "    precision = precision_score(sample_labels, predictions, zero_division=0)\n",
    "    recall = recall_score(sample_labels, predictions, zero_division=0)\n",
    "    f1 = f1_score(sample_labels, predictions, zero_division=0)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(sample_labels, predictions)\n",
    "    \n",
    "    # Classification report\n",
    "    class_report = classification_report(sample_labels, predictions, \n",
    "                                       target_names=['Human', 'AI'], \n",
    "                                       output_dict=True)\n",
    "    \n",
    "    print(f\"\\nüìà {model_name} RESULTS:\")\n",
    "    print(f\"‚è±Ô∏è  Total Time: {total_time:.2f} seconds\")\n",
    "    print(f\"‚ö° Samples/sec: {len(sample_texts)/total_time:.2f}\")\n",
    "    print(f\"üéØ Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"üîç Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
    "    print(f\"üé™ Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
    "    print(f\"üèÜ F1 Score:  {f1:.4f} ({f1*100:.2f}%)\")\n",
    "    \n",
    "    print(f\"\\nüìä Confusion Matrix:\")\n",
    "    print(f\"         Predicted\")\n",
    "    print(f\"         H    A\")\n",
    "    print(f\"Actual H {cm[0][0]:4d} {cm[0][1]:4d}\")\n",
    "    print(f\"       A {cm[1][0]:4d} {cm[1][1]:4d}\")\n",
    "    \n",
    "    # Save detailed results\n",
    "    results_df = pd.DataFrame(detailed_results)\n",
    "    \n",
    "    # Create a safe key for training log\n",
    "    log_key = model_name.lower().replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "    \n",
    "    # Store in training log\n",
    "    training_log[\"models\"][log_key] = {\n",
    "        \"model_name\": model_name,\n",
    "        \"model_id\": model_id,\n",
    "        \"evaluation_time\": total_time,\n",
    "        \"samples_evaluated\": len(sample_texts),\n",
    "        \"samples_per_second\": len(sample_texts)/total_time,\n",
    "        \"metrics\": {\n",
    "            \"accuracy\": float(accuracy),\n",
    "            \"precision\": float(precision),\n",
    "            \"recall\": float(recall),\n",
    "            \"f1_score\": float(f1)\n",
    "        },\n",
    "        \"confusion_matrix\": cm.tolist(),\n",
    "        \"classification_report\": class_report,\n",
    "        \"sample_results_saved\": f\"{model_name.lower().replace(' ', '_').replace('-', '_')}_detailed_results.csv\"\n",
    "    }\n",
    "    \n",
    "    return predictions, probabilities, results_df\n",
    "\n",
    "# Prepare sample data for evaluation\n",
    "if 'df' in locals() and len(df) > 0:\n",
    "    # Use simple preprocessing\n",
    "    sample_texts = df['text'].apply(lambda x: str(x)[:500]).head(1000)  # Limit text length\n",
    "    sample_labels = df['generated'].head(1000)\n",
    "    \n",
    "    print(f\"üéØ DATASET INFO:\")\n",
    "    print(f\"üìä Total samples: {len(sample_texts)}\")\n",
    "    print(f\"ü§ñ AI samples: {sum(sample_labels)} ({sum(sample_labels)/len(sample_labels)*100:.1f}%)\")\n",
    "    print(f\"üë§ Human samples: {len(sample_labels) - sum(sample_labels)} ({(len(sample_labels) - sum(sample_labels))/len(sample_labels)*100:.1f}%)\")\n",
    "    \n",
    "    # Evaluate each model and store results with consistent keys\n",
    "    model_results = {}\n",
    "    model_name_mapping = {}\n",
    "    \n",
    "    # Only evaluate the 2 successful models\n",
    "    if 'chatgpt_pipeline' in locals() and chatgpt_pipeline is not None:\n",
    "        chatgpt_preds, chatgpt_probs, chatgpt_df = evaluate_hf_model_with_progress(\n",
    "            chatgpt_pipeline, \"ChatGPT Detector RoBERTa\", \"Hello-SimpleAI/chatgpt-detector-roberta\",\n",
    "            sample_texts, sample_labels\n",
    "        )\n",
    "        model_results['chatgpt'] = {\n",
    "            'predictions': chatgpt_preds,\n",
    "            'probabilities': chatgpt_probs,\n",
    "            'detailed_df': chatgpt_df\n",
    "        }\n",
    "        model_name_mapping['chatgpt'] = 'chatgpt_detector_roberta'\n",
    "        \n",
    "        # Save detailed results\n",
    "        if chatgpt_df is not None:\n",
    "            chatgpt_df.to_csv('chatgpt_detailed_results.csv', index=False)\n",
    "            print(f\"üíæ Saved detailed results to 'chatgpt_detailed_results.csv'\")\n",
    "    \n",
    "    if 'openai_pipeline' in locals() and openai_pipeline is not None:\n",
    "        openai_preds, openai_probs, openai_df = evaluate_hf_model_with_progress(\n",
    "            openai_pipeline, \"OpenAI Community RoBERTa\", \"openai-community/roberta-base-openai-detector\",\n",
    "            sample_texts, sample_labels\n",
    "        )\n",
    "        model_results['openai'] = {\n",
    "            'predictions': openai_preds,\n",
    "            'probabilities': openai_probs,\n",
    "            'detailed_df': openai_df\n",
    "        }\n",
    "        model_name_mapping['openai'] = 'openai_community_roberta'\n",
    "        \n",
    "        # Save detailed results\n",
    "        if openai_df is not None:\n",
    "            openai_df.to_csv('openai_detailed_results.csv', index=False)\n",
    "            print(f\"üíæ Saved detailed results to 'openai_detailed_results.csv'\")\n",
    "    \n",
    "    # Overall summary with corrected key mapping\n",
    "    print(f\"\\nüèÜ OVERALL EVALUATION SUMMARY - 2 MODELS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if model_results:\n",
    "        # Create comparison DataFrame with proper key mapping\n",
    "        comparison_data = []\n",
    "        for model_key, results in model_results.items():\n",
    "            if results['predictions'] is not None:\n",
    "                log_key = model_name_mapping.get(model_key, model_key)\n",
    "                if log_key in training_log[\"models\"]:\n",
    "                    model_info = training_log[\"models\"][log_key]\n",
    "                    comparison_data.append({\n",
    "                        'Model': model_info['model_name'],\n",
    "                        'Accuracy': f\"{model_info['metrics']['accuracy']:.4f}\",\n",
    "                        'Precision': f\"{model_info['metrics']['precision']:.4f}\",\n",
    "                        'Recall': f\"{model_info['metrics']['recall']:.4f}\",\n",
    "                        'F1 Score': f\"{model_info['metrics']['f1_score']:.4f}\",\n",
    "                        'Speed (samples/sec)': f\"{model_info['samples_per_second']:.2f}\"\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Warning: Could not find training log for {model_key}\")\n",
    "        \n",
    "        if comparison_data:\n",
    "            comparison_df = pd.DataFrame(comparison_data)\n",
    "            print(comparison_df.to_string(index=False))\n",
    "            \n",
    "            # Save comparison\n",
    "            comparison_df.to_csv('model_comparison_results_2models.csv', index=False)\n",
    "            print(f\"\\nüíæ Saved comparison to 'model_comparison_results_2models.csv'\")\n",
    "        \n",
    "        # Save complete training log\n",
    "        with open('training_log_2models.json', 'w') as f:\n",
    "            json.dump(training_log, f, indent=2)\n",
    "        print(f\"üìã Saved complete training log to 'training_log_2models.json'\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ EVALUATION COMPLETED SUCCESSFULLY - 2 MODELS!\")\n",
    "        print(f\"üìÅ Files saved:\")\n",
    "        print(f\"   ‚Ä¢ training_log_2models.json - Complete evaluation log\")\n",
    "        print(f\"   ‚Ä¢ model_comparison_results_2models.csv - Summary comparison\")\n",
    "        print(f\"   ‚Ä¢ *_detailed_results.csv - Individual model results\")\n",
    "    else:\n",
    "        print(\"‚ùå No models were successfully evaluated!\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No dataset available for evaluation. Please load the dataset first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25791c7a",
   "metadata": {},
   "source": [
    "## Train and Evaluate BiLSTM Model\n",
    "\n",
    "We will use a Bidirectional LSTM (BiLSTM) neural network with word embeddings to classify the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a973af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Two Successful Models for Streamlit Application\n",
    "# Save only the 2 working Hugging Face models in a format compatible with Streamlit\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "print(\"üíæ Saving 2 successful models for Streamlit application...\")\n",
    "\n",
    "# Create a models directory\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Save model configurations and pipelines for only the 2 successful models\n",
    "model_configs = {\n",
    "    \"chatgpt\": {\n",
    "        \"name\": \"ChatGPT Detector RoBERTa\",\n",
    "        \"model_id\": \"Hello-SimpleAI/chatgpt-detector-roberta\", \n",
    "        \"description\": \"ChatGPT-specific content detector\",\n",
    "        \"pipeline\": chatgpt_pipeline\n",
    "    },\n",
    "    \"openai\": {\n",
    "        \"name\": \"OpenAI Community RoBERTa\",\n",
    "        \"model_id\": \"openai-community/roberta-base-openai-detector\",\n",
    "        \"description\": \"OpenAI content detection model\",\n",
    "        \"pipeline\": openai_pipeline\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save model configurations\n",
    "print(\"üìù Saving model configurations...\")\n",
    "with open(\"models/model_configs_2models.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_configs, f)\n",
    "\n",
    "# Save individual model information for Streamlit\n",
    "model_info = {\n",
    "    \"available_models\": [],\n",
    "    \"model_details\": {}\n",
    "}\n",
    "\n",
    "for key, config in model_configs.items():\n",
    "    if config[\"pipeline\"] is not None:\n",
    "        model_info[\"available_models\"].append(key)\n",
    "        model_info[\"model_details\"][key] = {\n",
    "            \"name\": config[\"name\"],\n",
    "            \"model_id\": config[\"model_id\"],\n",
    "            \"description\": config[\"description\"]\n",
    "        }\n",
    "        print(f\"‚úÖ {config['name']} - Ready for Streamlit\")\n",
    "    else:\n",
    "        print(f\"‚ùå {config['name']} - Failed to load\")\n",
    "\n",
    "# Save model info for Streamlit\n",
    "joblib.dump(model_info, \"model_info_2models.pkl\")\n",
    "print(f\"\\nüéâ Saved {len(model_info['available_models'])} models for Streamlit!\")\n",
    "\n",
    "# Save predictions if available\n",
    "if 'sample_texts' in locals():\n",
    "    predictions_data = {\n",
    "        \"sample_texts\": sample_texts.tolist()[:100],  # Save first 100 samples\n",
    "        \"true_labels\": sample_labels.tolist()[:100],\n",
    "    }\n",
    "    \n",
    "    if 'chatgpt_preds' in locals() and chatgpt_preds is not None:\n",
    "        predictions_data[\"chatgpt_predictions\"] = chatgpt_preds[:100] \n",
    "        predictions_data[\"chatgpt_probabilities\"] = chatgpt_probs[:100]\n",
    "    \n",
    "    if 'openai_preds' in locals() and openai_preds is not None:\n",
    "        predictions_data[\"openai_predictions\"] = openai_preds[:100]\n",
    "        predictions_data[\"openai_probabilities\"] = openai_probs[:100]\n",
    "    \n",
    "    # Save predictions\n",
    "    joblib.dump(predictions_data, \"sample_predictions_2models.pkl\")\n",
    "    print(\"üìä Sample predictions saved for analysis!\")\n",
    "\n",
    "print(\"\\nüöÄ 2 reliable models ready for Streamlit application!\")\n",
    "print(\"\\nüìã SUMMARY:\")\n",
    "print(\"   ‚Ä¢ ChatGPT Detector RoBERTa - Specialized for ChatGPT detection\")\n",
    "print(\"   ‚Ä¢ OpenAI Community RoBERTa - General OpenAI content detection\")\n",
    "print(f\"\\nüéØ Total: {len(model_info['available_models'])} working models saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efc7a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions and true labels to CSV files for all models\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure predictions and true labels are available\n",
    "if 'y_test' in locals():\n",
    "    # Save BiLSTM predictions\n",
    "    if 'y_pred_bilstm' in locals():\n",
    "        bilstm_output_df = pd.DataFrame({\n",
    "            'True Label': y_test,\n",
    "            'Predicted Label': y_pred_bilstm\n",
    "        })\n",
    "        bilstm_output_df.to_csv('bilstm_predictions.csv', index=False)\n",
    "        print(\"BiLSTM predictions saved to 'bilstm_predictions.csv'.\")\n",
    "\n",
    "    # Save Logistic Regression predictions\n",
    "    if 'y_pred_lr' in locals():\n",
    "        lr_output_df = pd.DataFrame({\n",
    "            'True Label': y_test,\n",
    "            'Predicted Label': y_pred_lr\n",
    "        })\n",
    "        lr_output_df.to_csv('logistic_regression_predictions.csv', index=False)\n",
    "        print(\"Logistic Regression predictions saved to 'logistic_regression_predictions.csv'.\")\n",
    "\n",
    "    # Save SVM predictions\n",
    "    if 'y_pred_svm' in locals():\n",
    "        svm_output_df = pd.DataFrame({\n",
    "            'True Label': y_test,\n",
    "            'Predicted Label': y_pred_svm\n",
    "        })\n",
    "        svm_output_df.to_csv('svm_predictions.csv', index=False)\n",
    "        print(\"SVM predictions saved to 'svm_predictions.csv'.\")\n",
    "\n",
    "    # Save BERT predictions\n",
    "    if 'y_pred_bert' in locals():\n",
    "        bert_output_df = pd.DataFrame({\n",
    "            'True Label': y_test,\n",
    "            'Predicted Label': y_pred_bert\n",
    "        })\n",
    "        bert_output_df.to_csv('bert_predictions.csv', index=False)\n",
    "        print(\"BERT predictions saved to 'bert_predictions.csv'.\")\n",
    "else:\n",
    "    print(\"Error: True labels are not available. Train and evaluate the models first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10981473",
   "metadata": {},
   "source": [
    "## Train and Evaluate BERT Model\n",
    "\n",
    "We will use a pre-trained BERT model (via Hugging Face Transformers) to classify the text. This approach uses transformer-based embeddings and fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0980b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Two Successful Models with Sample Texts\n",
    "# Quick test to verify both models are working correctly\n",
    "\n",
    "def test_models_with_samples():\n",
    "    \"\"\"Test the 2 successful models with sample texts\"\"\"\n",
    "    \n",
    "    print(\"üß™ Testing 2 successful models with sample texts...\")\n",
    "    \n",
    "    # Sample texts for testing\n",
    "    test_texts = [\n",
    "        \"This is a human-written text with natural flow and personal thoughts about the beautiful sunset.\",\n",
    "        \"The implementation of artificial intelligence systems requires careful consideration of various parameters and algorithmic approaches to achieve optimal performance metrics.\",\n",
    "        \"I really enjoyed the movie last night. The acting was superb and the plot kept me engaged throughout.\",\n",
    "        \"In conclusion, the methodology presented in this study demonstrates significant improvements in computational efficiency through the optimization of neural network architectures.\"\n",
    "    ]\n",
    "    \n",
    "    labels = [\"Human\", \"AI\", \"Human\", \"AI\"]  # Expected labels for comparison\n",
    "    \n",
    "    print(f\"\\nüìù Testing {len(test_texts)} sample texts...\")\n",
    "    \n",
    "    for i, text in enumerate(test_texts):\n",
    "        print(f\"\\n--- Sample {i+1} (Expected: {labels[i]}) ---\")\n",
    "        print(f\"Text: {text[:80]}...\")\n",
    "        \n",
    "        # Test ChatGPT detector\n",
    "        if 'chatgpt_pipeline' in locals() and chatgpt_pipeline:\n",
    "            try:\n",
    "                result = chatgpt_pipeline(text)\n",
    "                if isinstance(result, list):\n",
    "                    result = result[0]\n",
    "                label = result.get('label', 'UNKNOWN')\n",
    "                score = result.get('score', 0.0)\n",
    "                print(f\"ü§ñ ChatGPT: {label} (confidence: {score:.3f})\")\n",
    "            except Exception as e:\n",
    "                print(f\"ü§ñ ChatGPT: Error - {e}\")\n",
    "        \n",
    "        # Test OpenAI detector\n",
    "        if 'openai_pipeline' in locals() and openai_pipeline:\n",
    "            try:\n",
    "                result = openai_pipeline(text)\n",
    "                if isinstance(result, list):\n",
    "                    result = result[0]\n",
    "                label = result.get('label', 'UNKNOWN')\n",
    "                score = result.get('score', 0.0)\n",
    "                print(f\"üîç OpenAI: {label} (confidence: {score:.3f})\")\n",
    "            except Exception as e:\n",
    "                print(f\"üîç OpenAI: Error - {e}\")\n",
    "\n",
    "# Run the test\n",
    "test_models_with_samples()\n",
    "\n",
    "print(\"\\n‚úÖ Testing completed for 2 successful models!\")\n",
    "print(\"\\nüìä ACTIVE MODELS:\")\n",
    "if 'chatgpt_pipeline' in locals() and chatgpt_pipeline:\n",
    "    print(\"   ‚úÖ ChatGPT Detector RoBERTa - Ready\")\n",
    "if 'openai_pipeline' in locals() and openai_pipeline:\n",
    "    print(\"   ‚úÖ OpenAI Community RoBERTa - Ready\")\n",
    "\n",
    "print(f\"\\nüéØ Both models are working and ready for use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f40d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging: Check shapes of tokenized inputs\n",
    "if 'X_train_bert' in locals():\n",
    "    print(\"Shape of X_train_bert:\", X_train_bert.shape)\n",
    "    print(\"Shape of X_test_bert:\", X_test_bert.shape)\n",
    "    print(\"Sample of X_train_bert[0]:\", X_train_bert[0][:10])  # Show first 10 tokens\n",
    "else:\n",
    "    print(\"X_train_bert not defined yet. Run the BERT encoding cell first.\")\n",
    "\n",
    "# Debugging: Check if BERT tokenizer is working\n",
    "try:\n",
    "    from transformers import AutoTokenizer\n",
    "    bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "    print(\"BERT tokenizer loaded successfully.\")\n",
    "    print(\"Vocab size:\", bert_tokenizer.vocab_size)\n",
    "except Exception as e:\n",
    "    print(\"Error loading BERT tokenizer:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d31ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure TF-IDF vectorizer and train-test split are defined\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create TF-IDF features\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = vectorizer.fit_transform(df['text_clean'])  # Use preprocessed text\n",
    "y = df['generated']  # Labels (0 = Human, 1 = AI)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train SVM\n",
    "print(\"Training SVM...\")\n",
    "svm = SVC()\n",
    "svm.fit(X_train_tfidf, y_train)\n",
    "y_pred_svm = svm.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate SVM\n",
    "show_metrics('SVM (TF-IDF)', y_test, y_pred_svm)\n",
    "\n",
    "# Save the SVM model\n",
    "import joblib\n",
    "joblib.dump(svm, \"svm_model.pkl\")\n",
    "print(\"SVM model saved as 'svm_model.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08b3dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Train SGDClassifier with progress tracking\n",
    "print(\"Training SGDClassifier...\")\n",
    "sgd = SGDClassifier()\n",
    "for epoch in tqdm(range(10), desc=\"SGD Training Progress\"):\n",
    "    sgd.partial_fit(X_train_tfidf, y_train, classes=np.unique(y_train))\n",
    "\n",
    "y_pred_sgd = sgd.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate SGDClassifier\n",
    "show_metrics('SGDClassifier (TF-IDF)', y_test, y_pred_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a492fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the TF-IDF vectorizer for later use\n",
    "import joblib\n",
    "\n",
    "# Ensure the vectorizer is trained before saving\n",
    "if 'vectorizer' in locals():\n",
    "    joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
    "    print(\"TF-IDF vectorizer saved as 'tfidf_vectorizer.pkl'.\")\n",
    "else:\n",
    "    print(\"Error: TF-IDF vectorizer is not defined. Train the vectorizer before saving.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8600aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the AI-generated essay dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = 'AI Generated Essays Dataset.csv'\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X = data['text']\n",
    "y = data['generated']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the text data using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = logistic_model.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the trained model and vectorizer\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')\n",
    "joblib.dump(logistic_model, 'logistic_regression_model.pkl')\n",
    "print(\"Model and vectorizer saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
